{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599d6a8f",
   "metadata": {},
   "source": [
    "garb some knowledge about json\n",
    "like dumps and load\n",
    "os.listdir and os.path.join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40d3969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".git\n",
      ".gitignore\n",
      "data\n",
      "LICENSE\n",
      "README.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_path=\"C:\\\\Users\\\\Dell\\\\OneDrive - Havells\\\\Desktop\\\\DataScience\\\\pulse\"\n",
    "for i in os.listdir(base_path):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7d689",
   "metadata": {},
   "source": [
    "Aggreated Insurance 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed9ef2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\aggregated\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\aggregated\\insurance\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\aggregated\\insurance\\country\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\aggregated\\insurance\\country\\india\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\aggregated\\insurance\\country\\india\\state\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "base_path=\"C:\\\\Users\\\\Dell\\\\OneDrive - Havells\\\\Desktop\\\\DataScience\\\\pulse\"\n",
    "data=[]\n",
    "for i in os.listdir(base_path):\n",
    "    data.append(i) \n",
    "      \n",
    "data1=data[2]  \n",
    "data_path=os.path.join(base_path,data1)\n",
    "amt=[]\n",
    "for i in os.listdir(data_path):\n",
    "    amt.append(i)\n",
    "    \n",
    "amt=amt[0]\n",
    "amu_path=os.path.join(data_path,amt)\n",
    "print(amu_path)\n",
    "\n",
    "uti=[]\n",
    "for i in os.listdir(amu_path):\n",
    "    uti.append(i)\n",
    "    \n",
    "uti=uti[0] \n",
    "transaction_path=os.path.join(amu_path,uti)\n",
    "\n",
    "print(transaction_path)\n",
    "\n",
    "country=[]\n",
    "for i in os.listdir(transaction_path):\n",
    "    country.append(i)\n",
    "country=country[0]    \n",
    "country_path=os.path.join(transaction_path,country)    \n",
    "print(country_path)\n",
    "india=[]\n",
    "for i in os.listdir(country_path):\n",
    "    india.append(i)\n",
    "india=india[0]    \n",
    "india_path=os.path.join(country_path,india)   \n",
    "print(india_path)\n",
    "lst=[]\n",
    "for i in os.listdir(india_path):\n",
    "    lst.append(i)\n",
    "lst=lst[5]  \n",
    "state_path=os.path.join(india_path,lst)  \n",
    "print(state_path)\n",
    "\n",
    "insurance_data=[]\n",
    "for state in os.listdir(state_path):\n",
    "    state1_path=os.path.join(state_path,state)\n",
    "    \n",
    "    for year in os.listdir(state1_path):\n",
    "        year_path=os.path.join(state1_path,year)\n",
    "        \n",
    "        for file in os.listdir(year_path):\n",
    "            file_path=os.path.join(year_path,file)\n",
    "            quater=int(file.replace(\".json\",\"\"))\n",
    "            \n",
    "            with open (file_path,\"r\") as f:\n",
    "                data=json.load(f)\n",
    "                \n",
    "                \n",
    "                if data[\"data\"]:\n",
    "                    for i in data[\"data\"][\"transactionData\"]:\n",
    "                        insurance_name=i[\"name\"]\n",
    "                        insurance_count=i[\"paymentInstruments\"][0][\"count\"]\n",
    "                        insurance_amount=i[\"paymentInstruments\"][0][\"amount\"]\n",
    "                        \n",
    "                    \n",
    "                    \n",
    "                        insurance_data.append({\n",
    "                        \"State\":state,\n",
    "                        \"Year\":year,\n",
    "                        \"Quarter\":quater,\n",
    "                        \"name\":insurance_name,\n",
    "                        \"insurance_count\":insurance_count,\n",
    "                        \"insurance_amount\":insurance_amount})\n",
    "import pandas as pd            \n",
    "dataset_aggreated_insurance=pd.DataFrame(insurance_data) \n",
    "dataset_aggreated_insurance \n",
    "\n",
    "dataset_aggreated_insurance.to_csv(\"aggreated_insurance.csv\",index=False)             \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049266b3",
   "metadata": {},
   "source": [
    "Aggreated Transaction  2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c370f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\aggregated\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\aggregated\\transaction\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\aggregated\\transaction\\country\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\aggregated\\transaction\\country\\india\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\aggregated\\transaction\\country\\india\\state\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "base_path=\"C:\\\\Users\\\\Dell\\\\OneDrive - Havells\\\\Desktop\\\\DataScience\\\\pulse\"\n",
    "data=[]\n",
    "for i in os.listdir(base_path):\n",
    "    data.append(i) \n",
    "      \n",
    "data1=data[2]  \n",
    "data_path=os.path.join(base_path,data1)\n",
    "amt=[]\n",
    "for i in os.listdir(data_path):\n",
    "    amt.append(i)\n",
    "    \n",
    "amt=amt[0]\n",
    "amu_path=os.path.join(data_path,amt)\n",
    "print(amu_path)\n",
    "\n",
    "uti=[]\n",
    "for i in os.listdir(amu_path):\n",
    "    uti.append(i)\n",
    "    \n",
    "uti=uti[1] \n",
    "transaction_path=os.path.join(amu_path,uti)\n",
    "\n",
    "print(transaction_path)\n",
    "\n",
    "country=[]\n",
    "for i in os.listdir(transaction_path):\n",
    "    country.append(i)\n",
    "country=country[0]    \n",
    "country_path=os.path.join(transaction_path,country)    \n",
    "print(country_path)\n",
    "india=[]\n",
    "for i in os.listdir(country_path):\n",
    "    india.append(i)\n",
    "india=india[0]    \n",
    "india_path=os.path.join(country_path,india)   \n",
    "print(india_path)\n",
    "lst=[]\n",
    "for i in os.listdir(india_path):\n",
    "    lst.append(i)\n",
    "lst=lst[7]  \n",
    "state_path=os.path.join(india_path,lst)  \n",
    "print(state_path)\n",
    "\n",
    "transaction_data=[]\n",
    "for state in os.listdir(state_path):\n",
    "    state1_path=os.path.join(state_path,state)\n",
    "    \n",
    "    for year in os.listdir(state1_path):\n",
    "        year_path=os.path.join(state1_path,year)\n",
    "        \n",
    "        for file in os.listdir(year_path):\n",
    "            file_path=os.path.join(year_path,file)\n",
    "            quater=int(file.replace(\".json\",\"\"))\n",
    "            \n",
    "            with open (file_path,\"r\") as f:\n",
    "                data=json.load(f)\n",
    "                \n",
    "                if data[\"data\"]:\n",
    "                    for i in data[\"data\"][\"transactionData\"]:\n",
    "                        transaction_name=i[\"name\"]\n",
    "                        transaction_count=i[\"paymentInstruments\"][0][\"count\"]\n",
    "                        transaction_amount=i[\"paymentInstruments\"][0][\"amount\"]\n",
    "                    \n",
    "                        transaction_data.append({\n",
    "                        \"State\":state,\n",
    "                        \"Year\":year,\n",
    "                        \"Quarter\":quater,\n",
    "                        \"transaction_name\":transaction_name,\n",
    "                        \"transaction_count\":transaction_count,\n",
    "                        \"transaction_amount\":transaction_amount})\n",
    "import pandas as pd            \n",
    "dataset_aggreated_transaction=pd.DataFrame(transaction_data) \n",
    "dataset_aggreated_transaction             \n",
    "\n",
    "dataset_aggreated_transaction.to_csv(\"aggreated_transaction.csv\",index=False)                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20ac72b",
   "metadata": {},
   "source": [
    "Aggreated users 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c03cdfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\aggregated\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\aggregated\\user\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\aggregated\\user\\country\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\aggregated\\user\\country\\india\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\aggregated\\user\\country\\india\\state\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>registered_users</th>\n",
       "      <th>app_opens</th>\n",
       "      <th>brand</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andaman-&amp;-nicobar-islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>6740</td>\n",
       "      <td>0</td>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>1665</td>\n",
       "      <td>0.247033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andaman-&amp;-nicobar-islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>6740</td>\n",
       "      <td>0</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>1445</td>\n",
       "      <td>0.214392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andaman-&amp;-nicobar-islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>6740</td>\n",
       "      <td>0</td>\n",
       "      <td>Vivo</td>\n",
       "      <td>982</td>\n",
       "      <td>0.145697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andaman-&amp;-nicobar-islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>6740</td>\n",
       "      <td>0</td>\n",
       "      <td>Oppo</td>\n",
       "      <td>501</td>\n",
       "      <td>0.074332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andaman-&amp;-nicobar-islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>6740</td>\n",
       "      <td>0</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>332</td>\n",
       "      <td>0.049258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6727</th>\n",
       "      <td>west-bengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>21919787</td>\n",
       "      <td>236131065</td>\n",
       "      <td>Lenovo</td>\n",
       "      <td>330017</td>\n",
       "      <td>0.015056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6728</th>\n",
       "      <td>west-bengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>21919787</td>\n",
       "      <td>236131065</td>\n",
       "      <td>Infinix</td>\n",
       "      <td>284678</td>\n",
       "      <td>0.012987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6729</th>\n",
       "      <td>west-bengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>21919787</td>\n",
       "      <td>236131065</td>\n",
       "      <td>Asus</td>\n",
       "      <td>280347</td>\n",
       "      <td>0.012790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730</th>\n",
       "      <td>west-bengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>21919787</td>\n",
       "      <td>236131065</td>\n",
       "      <td>Apple</td>\n",
       "      <td>277752</td>\n",
       "      <td>0.012671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6731</th>\n",
       "      <td>west-bengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>21919787</td>\n",
       "      <td>236131065</td>\n",
       "      <td>Others</td>\n",
       "      <td>2196334</td>\n",
       "      <td>0.100199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6732 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          State  Year  Quarter  registered_users  app_opens  \\\n",
       "0     andaman-&-nicobar-islands  2018        1              6740          0   \n",
       "1     andaman-&-nicobar-islands  2018        1              6740          0   \n",
       "2     andaman-&-nicobar-islands  2018        1              6740          0   \n",
       "3     andaman-&-nicobar-islands  2018        1              6740          0   \n",
       "4     andaman-&-nicobar-islands  2018        1              6740          0   \n",
       "...                         ...   ...      ...               ...        ...   \n",
       "6727                west-bengal  2022        1          21919787  236131065   \n",
       "6728                west-bengal  2022        1          21919787  236131065   \n",
       "6729                west-bengal  2022        1          21919787  236131065   \n",
       "6730                west-bengal  2022        1          21919787  236131065   \n",
       "6731                west-bengal  2022        1          21919787  236131065   \n",
       "\n",
       "        brand    count  percentage  \n",
       "0      Xiaomi     1665    0.247033  \n",
       "1     Samsung     1445    0.214392  \n",
       "2        Vivo      982    0.145697  \n",
       "3        Oppo      501    0.074332  \n",
       "4     OnePlus      332    0.049258  \n",
       "...       ...      ...         ...  \n",
       "6727   Lenovo   330017    0.015056  \n",
       "6728  Infinix   284678    0.012987  \n",
       "6729     Asus   280347    0.012790  \n",
       "6730    Apple   277752    0.012671  \n",
       "6731   Others  2196334    0.100199  \n",
       "\n",
       "[6732 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "base_path=\"C:\\\\Users\\\\Dell\\\\OneDrive - Havells\\\\Desktop\\\\DataScience\\\\pulse\"\n",
    "data=[]\n",
    "for i in os.listdir(base_path):\n",
    "    data.append(i) \n",
    "      \n",
    "data1=data[2]  \n",
    "data_path=os.path.join(base_path,data1)\n",
    "amu=[]\n",
    "for i in os.listdir(data_path):\n",
    "    amu.append(i)\n",
    "    \n",
    "amu=amu[0]\n",
    "amu_path=os.path.join(data_path,amu)\n",
    "print(amu_path)\n",
    "\n",
    "uti=[]\n",
    "for i in os.listdir(amu_path):\n",
    "    uti.append(i)\n",
    "    \n",
    "uti=uti[2] \n",
    "user_path=os.path.join(amu_path,uti)\n",
    "\n",
    "print(user_path)\n",
    "\n",
    "country=[]\n",
    "for i in os.listdir(user_path):\n",
    "    country.append(i)\n",
    "country=country[0]    \n",
    "country_path=os.path.join(user_path,country)    \n",
    "print(country_path)\n",
    "india=[]\n",
    "for i in os.listdir(country_path):\n",
    "    india.append(i)\n",
    "    \n",
    "india=india[0] \n",
    "india_path=os.path.join(country_path,india)   \n",
    "print(india_path)\n",
    "lst=[]\n",
    "for i in os.listdir(india_path):\n",
    "    lst.append(i)\n",
    "lst=lst[7]  \n",
    "state_path=os.path.join(india_path,lst)  \n",
    "print(state_path)\n",
    "\n",
    "user_data=[]\n",
    "for state in os.listdir(state_path):\n",
    "    state1_path=os.path.join(state_path,state)\n",
    "    \n",
    "    for year in os.listdir(state1_path):\n",
    "        year_path=os.path.join(state1_path,year)\n",
    "        \n",
    "        for file in os.listdir(year_path):\n",
    "           file_path=os.path.join(year_path,file)\n",
    "            \n",
    "           with open(file_path,\"r\") as f:\n",
    "                data=json.load(f)\n",
    "                quater=int(file.replace(\".json\",\"\"))\n",
    "                \n",
    "                if data[\"data\"]:\n",
    "                    registered_users=data[\"data\"][\"aggregated\"][\"registeredUsers\"]\n",
    "                    appOpens=data[\"data\"][\"aggregated\"][\"appOpens\"]\n",
    "                    \n",
    "                    if data[\"data\"][\"usersByDevice\"]:\n",
    "                        for i in data[\"data\"][\"usersByDevice\"]:\n",
    "                            brand=i[\"brand\"]\n",
    "                            count=i[\"count\"]\n",
    "                            percentage=i[\"percentage\"]\n",
    "                        \n",
    "                \n",
    "                            user_data.append({\n",
    "                           \"State\":state,\n",
    "                           \"Year\":year,\n",
    "                            \"Quarter\":quater,\n",
    "                            \"registered_users\":registered_users,\n",
    "                            \"app_opens\":appOpens,\n",
    "                            \"brand\":brand,\n",
    "                             \"count\":count,\n",
    "                            \"percentage\":percentage})\n",
    "                 \n",
    "import pandas as pd\n",
    "dataset_aggreated_user=pd.DataFrame(user_data)  \n",
    "dataset_aggreated_user          \n",
    "\n",
    "#dataset_aggreated_user.to_csv(\"aggreated_user.csv\",index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd34e919",
   "metadata": {},
   "source": [
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87da0d07",
   "metadata": {},
   "source": [
    "Map insurance   4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22406f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\\insurance\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\\insurance\\hover\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\\insurance\\hover\\country\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\\insurance\\hover\\country\\india\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\\insurance\\hover\\country\\india\\state\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "base_path=\"C:\\\\Users\\\\Dell\\\\OneDrive - Havells\\\\Desktop\\\\DataScience\\\\pulse\"\n",
    "data=[]\n",
    "for i in os.listdir(base_path):\n",
    "    data.append(i) \n",
    "      \n",
    "data1=data[2]  \n",
    "data_path=os.path.join(base_path,data1)\n",
    "amu=[]\n",
    "for i in os.listdir(data_path):\n",
    "    amu.append(i)\n",
    "    \n",
    "amu=amu[1]\n",
    "amu_path=os.path.join(data_path,amu)\n",
    "print(amu_path)\n",
    "\n",
    "uti=[]\n",
    "for i in os.listdir(amu_path):\n",
    "    uti.append(i)\n",
    "    \n",
    "uti=uti[0] \n",
    "user_path=os.path.join(amu_path,uti)\n",
    "\n",
    "print(user_path)\n",
    "\n",
    "hover=[]\n",
    "for i in os.listdir(user_path):\n",
    "    hover.append(i)\n",
    "hover=hover[1]    \n",
    "hover_path=os.path.join(user_path,hover)    \n",
    "print(hover_path)\n",
    "country=[]\n",
    "for i in os.listdir(hover_path):\n",
    "    country.append(i)\n",
    "country=country[0]\n",
    "country_path=os.path.join(hover_path,country)\n",
    "print(country_path)\n",
    "india=[]\n",
    "for i in os.listdir(country_path):\n",
    "    india.append(i)\n",
    "    \n",
    "india=india[0] \n",
    "india_path=os.path.join(country_path,india)   \n",
    "print(india_path)\n",
    "lst=[]\n",
    "for i in os.listdir(india_path):\n",
    "    lst.append(i)\n",
    "lst=lst[5]  \n",
    "state_path=os.path.join(india_path,lst)  \n",
    "print(state_path)\n",
    "\n",
    "insurance_data=[]\n",
    "for state in os.listdir(state_path):\n",
    "    state1_path=os.path.join(state_path,state)\n",
    "    \n",
    "    for year in os.listdir(state1_path):\n",
    "        year_path=os.path.join(state1_path,year)\n",
    "        \n",
    "        for file in os.listdir(year_path):\n",
    "            file_path=os.path.join(year_path,file)\n",
    "            quater=int(file.replace(\".json\",\"\"))\n",
    "            \n",
    "            with open (file_path,\"r\") as f:\n",
    "                data=json.load(f)\n",
    "                \n",
    "                if data[\"data\"] and \"hoverDataList\" in data[\"data\"]:\n",
    "                    for  item in data[\"data\"][\"hoverDataList\"]:\n",
    "                        name=item[\"name\"]\n",
    "                        count=item[\"metric\"][0][\"count\"]\n",
    "                        amount=item[\"metric\"][0][\"amount\"]\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        insurance_data.append({\n",
    "                            \"State\":state,\n",
    "                            \"Year\":year,\n",
    "                            \"Quarter\":quater,\n",
    "                            \"name\":name,\n",
    "                            \"insurance_count\":count,\n",
    "                            \"insurance_amount\":amount\n",
    "                        })\n",
    "import pandas as pd\n",
    "dataset_map_insurance=pd.DataFrame(insurance_data)  \n",
    "dataset_map_insurance                          \n",
    "    \n",
    "dataset_map_insurance.to_csv(\"map_insurance.csv\",index=False)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea52fb",
   "metadata": {},
   "source": [
    "Map Transaction 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "365370fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\\transaction\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\\transaction\\hover\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\\transaction\\hover\\country\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\\transaction\\hover\\country\\india\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\\transaction\\hover\\country\\india\\state\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "base_path=\"C:\\\\Users\\\\Dell\\\\OneDrive - Havells\\\\Desktop\\\\DataScience\\\\pulse\"\n",
    "data=[]\n",
    "for i in os.listdir(base_path):\n",
    "    data.append(i) \n",
    "      \n",
    "data1=data[2]  \n",
    "data_path=os.path.join(base_path,data1)\n",
    "amu=[]\n",
    "for i in os.listdir(data_path):\n",
    "    amu.append(i)\n",
    "    \n",
    "amu=amu[1]\n",
    "amu_path=os.path.join(data_path,amu)\n",
    "print(amu_path)\n",
    "\n",
    "uti=[]\n",
    "for i in os.listdir(amu_path):\n",
    "    uti.append(i)\n",
    "        \n",
    "uti=uti[1] \n",
    "user_path=os.path.join(amu_path,uti)\n",
    "\n",
    "print(user_path)\n",
    "\n",
    "hover=[]\n",
    "for i in os.listdir(user_path):\n",
    "    hover.append(i)\n",
    "hover=hover[0]    \n",
    "hover_path=os.path.join(user_path,hover)    \n",
    "print(hover_path)\n",
    "country=[]\n",
    "for i in os.listdir(hover_path):\n",
    "    country.append(i)\n",
    "country=country[0]\n",
    "country_path=os.path.join(hover_path,country)\n",
    "print(country_path)\n",
    "india=[]\n",
    "for i in os.listdir(country_path):\n",
    "    india.append(i)\n",
    "    \n",
    "india=india[0] \n",
    "india_path=os.path.join(country_path,india)   \n",
    "print(india_path)\n",
    "lst=[]\n",
    "for i in os.listdir(india_path):\n",
    "    lst.append(i)\n",
    "lst=lst[7]  \n",
    "state_path=os.path.join(india_path,lst)  \n",
    "print(state_path)\n",
    "\n",
    "transaction_data=[]\n",
    "for state in os.listdir(state_path):\n",
    "    state1_path=os.path.join(state_path,state)\n",
    "    \n",
    "    for year in os.listdir(state1_path):\n",
    "        year_path=os.path.join(state1_path,year)\n",
    "        \n",
    "        for file in os.listdir(year_path):\n",
    "            file_path=os.path.join(year_path,file)\n",
    "            quater=int(file.replace(\".json\",\"\"))\n",
    "            \n",
    "            with open (file_path,\"r\") as f:\n",
    "                data=json.load(f)\n",
    "                \n",
    "                if data[\"data\"] and \"hoverDataList\" in data[\"data\"]:\n",
    "                    for  item in data[\"data\"][\"hoverDataList\"]:\n",
    "                        name=item[\"name\"]\n",
    "                        count=item[\"metric\"][0][\"count\"]\n",
    "                        amount=item[\"metric\"][0][\"amount\"]\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        transaction_data.append({\n",
    "                            \"State\":state,\n",
    "                            \"Year\":year,\n",
    "                            \"Quater\":quater,\n",
    "                            \"name\":name,\n",
    "                            \"transaction_count\":count,\n",
    "                            \"transaction_amount\":amount\n",
    "                        })\n",
    "import pandas as pd\n",
    "dataset_map_transaction=pd.DataFrame(transaction_data)  \n",
    "dataset_map_transaction \n",
    "\n",
    "dataset_map_transaction.to_csv(\"map_transaction.csv\",index=False)                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f835b059",
   "metadata": {},
   "source": [
    "Map user 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ece3ef08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aggregated', 'map', 'top']\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\\user\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\\user\\hover\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\\user\\hover\\country\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\\user\\hover\\country\\india\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\map\\user\\hover\\country\\india\\state\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "base_path=\"C:\\\\Users\\\\Dell\\\\OneDrive - Havells\\\\Desktop\\\\DataScience\\\\pulse\"\n",
    "data=[]\n",
    "for i in os.listdir(base_path):\n",
    "    data.append(i) \n",
    "      \n",
    "data1=data[2]  \n",
    "data_path=os.path.join(base_path,data1)\n",
    "amu=[]\n",
    "for i in os.listdir(data_path):\n",
    "    amu.append(i)\n",
    "print(amu)     \n",
    "amu=amu[1]\n",
    "amu_path=os.path.join(data_path,amu)\n",
    "print(amu_path)\n",
    "\n",
    "uti=[]\n",
    "for i in os.listdir(amu_path):\n",
    "    uti.append(i)\n",
    "        \n",
    "uti=uti[2] \n",
    "user_path=os.path.join(amu_path,uti)\n",
    "\n",
    "print(user_path)\n",
    "\n",
    "hover=[]\n",
    "for i in os.listdir(user_path):\n",
    "    hover.append(i)\n",
    "hover=hover[0]    \n",
    "hover_path=os.path.join(user_path,hover)    \n",
    "print(hover_path)\n",
    "country=[]\n",
    "for i in os.listdir(hover_path):\n",
    "    country.append(i)\n",
    "country=country[0]\n",
    "country_path=os.path.join(hover_path,country)\n",
    "print(country_path)\n",
    "india=[]\n",
    "for i in os.listdir(country_path):\n",
    "    india.append(i)\n",
    "    \n",
    "india=india[0] \n",
    "india_path=os.path.join(country_path,india)   \n",
    "print(india_path)\n",
    "lst=[]\n",
    "for i in os.listdir(india_path):\n",
    "    lst.append(i)\n",
    "lst=lst[7]  \n",
    "state_path=os.path.join(india_path,lst)  \n",
    "print(state_path)\n",
    "\n",
    "user_data=[]\n",
    "for state in os.listdir(state_path):\n",
    "    state1_path=os.path.join(state_path,state)\n",
    "    \n",
    "    for year in os.listdir(state1_path):\n",
    "        year_path=os.path.join(state1_path,year)\n",
    "        \n",
    "        for file in os.listdir(year_path):\n",
    "            file_path=os.path.join(year_path,file)\n",
    "            quater=int(file.replace(\".json\",\"\"))\n",
    "            \n",
    "            with open (file_path,\"r\") as f:\n",
    "                data=json.load(f)\n",
    "            \n",
    "                \n",
    "                hover_data=data.get(\"data\",{}).get(\"hoverData\",{})\n",
    "                for district_name,metrics in hover_data.items():\n",
    "                    registered_users=metrics.get(\"registeredUsers\",0)\n",
    "                    app_opens=metrics.get(\"appOpens\",0)\n",
    "                    \n",
    "                           \n",
    "                    user_data.append({\n",
    "                            \"State\":state,\n",
    "                            \"Year\":year,\n",
    "                            \"Quater\":quater,\n",
    "                            \"district\":district_name.title(),\n",
    "                            \"registered_users\":registered_users,\n",
    "                            \"app_opens\":app_opens\n",
    "                        })\n",
    "#import pandas as pd\n",
    "dataset_map_user=pd.DataFrame(user_data)  \n",
    "dataset_map_user \n",
    "dataset_map_user.to_csv(\"map_user.csv\",index=False)\n",
    "#import pandas as pd\n",
    "\n",
    "#df = pd.json_normalize(data, sep='.')\n",
    "#pd.json_normalize(\n",
    "    #data,\n",
    "    #sep='.',\n",
    "    #max_level=3  # Adjust this if you want deeper levels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98e3986",
   "metadata": {},
   "source": [
    "Top Insurance 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96683a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\top\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\top\\insurance\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\top\\insurance\\country\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\top\\insurance\\country\\india\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\top\\insurance\\country\\india\\state\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "base_path=\"C:\\\\Users\\\\Dell\\\\OneDrive - Havells\\\\Desktop\\\\DataScience\\\\pulse\"\n",
    "data=[]\n",
    "for i in os.listdir(base_path):\n",
    "    data.append(i) \n",
    "      \n",
    "data1=data[2]  \n",
    "data_path=os.path.join(base_path,data1)\n",
    "amu=[]\n",
    "for i in os.listdir(data_path):\n",
    "    amu.append(i)\n",
    "     \n",
    "amu=amu[2]\n",
    "amu_path=os.path.join(data_path,amu)\n",
    "print(amu_path)\n",
    "\n",
    "uti=[]\n",
    "for i in os.listdir(amu_path):\n",
    "    uti.append(i)\n",
    "      \n",
    "uti=uti[0] \n",
    "user_path=os.path.join(amu_path,uti)\n",
    "\n",
    "print(user_path)\n",
    "\n",
    "country=[]\n",
    "for i in os.listdir(user_path):\n",
    "    country.append(i)\n",
    "country=country[0]\n",
    "country_path=os.path.join(user_path,country)\n",
    "print(country_path)\n",
    "india=[]\n",
    "for i in os.listdir(country_path):\n",
    "    india.append(i)\n",
    "    \n",
    "india=india[0] \n",
    "india_path=os.path.join(country_path,india)   \n",
    "print(india_path)\n",
    "lst=[]\n",
    "for i in os.listdir(india_path):\n",
    "    lst.append(i)\n",
    "lst=lst[5]  \n",
    "state_path=os.path.join(india_path,lst)  \n",
    "print(state_path)\n",
    "\n",
    "insurance_data=[]\n",
    "for state in os.listdir(state_path):\n",
    "    state1_path=os.path.join(state_path,state)\n",
    "    \n",
    "    for year in os.listdir(state1_path):\n",
    "        year_path=os.path.join(state1_path,year)\n",
    "        \n",
    "        for file in os.listdir(year_path):\n",
    "            file_path=os.path.join(year_path,file)\n",
    "            quater=int(file.replace(\".json\",\"\"))\n",
    "            \n",
    "            with open (file_path,\"r\") as f:\n",
    "                data=json.load(f)\n",
    "                \n",
    "                if data.get(\"data\"):\n",
    "                    for d in data[\"data\"][\"districts\"]:\n",
    "                        entity_name_district=d[\"entityName\"]\n",
    "                        count_districts=d[\"metric\"][\"count\"]\n",
    "                        amount_district=d[\"metric\"][\"amount\"]\n",
    "                        \n",
    "                        \n",
    "                    if data.get(\"data\"):\n",
    "                        for p in data[\"data\"][\"pincodes\"]:\n",
    "                            entity_name_pincodes=p[\"entityName\"]   \n",
    "                            count_pincode=p[\"metric\"][\"count\"]\n",
    "                            amount_pincode=p[\"metric\"][\"amount\"]\n",
    "                        \n",
    "                            insurance_data.append({\n",
    "                            \"State\":state,\n",
    "                            \"Year\":year,\n",
    "                            \"Quater\":quater,\n",
    "                            \"District_entity_name\":entity_name_district,\n",
    "                            \"District_count\":count_districts,\n",
    "                            \"District_amount\":amount_district,\n",
    "                            \"pincode_entity_name\":entity_name_pincodes,\n",
    "                            \"pincode_count\":count_pincode,\n",
    "                            \"pincode_amount\":amount_pincode})\n",
    "                                           \n",
    "import pandas as pd\n",
    "dataset_top_insurance=pd.DataFrame(insurance_data)  \n",
    "dataset_top_insurance\n",
    "\n",
    "dataset_top_insurance.to_csv(\"top_insurance.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187f374f",
   "metadata": {},
   "source": [
    "Top transaction  8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18817634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.gitignore', 'data', 'LICENSE', 'README.md']\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\top\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\top\\transaction\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\top\\transaction\\country\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\top\\transaction\\country\\india\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\top\\transaction\\country\\india\\state\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "base_path=\"C:\\\\Users\\\\Dell\\\\OneDrive - Havells\\\\Desktop\\\\DataScience\\\\pulse\"\n",
    "data=[]\n",
    "for i in os.listdir(base_path):\n",
    "    data.append(i) \n",
    "print(data)     \n",
    "data1=data[2]  \n",
    "data_path=os.path.join(base_path,data1)\n",
    "print(data_path)\n",
    "amu=[]\n",
    "for i in os.listdir(data_path):\n",
    "    amu.append(i)\n",
    "     \n",
    "amu=amu[2]\n",
    "amu_path=os.path.join(data_path,amu)\n",
    "print(amu_path)\n",
    "\n",
    "uti=[]\n",
    "for i in os.listdir(amu_path):\n",
    "    uti.append(i)\n",
    "      \n",
    "uti=uti[1] \n",
    "user_path=os.path.join(amu_path,uti)\n",
    "\n",
    "print(user_path)\n",
    "\n",
    "country=[]\n",
    "for i in os.listdir(user_path):\n",
    "    country.append(i)\n",
    "country=country[0]\n",
    "country_path=os.path.join(user_path,country)\n",
    "print(country_path)\n",
    "india=[]\n",
    "for i in os.listdir(country_path):\n",
    "    india.append(i)\n",
    "    \n",
    "india=india[0] \n",
    "india_path=os.path.join(country_path,india)   \n",
    "print(india_path)\n",
    "lst=[]\n",
    "for i in os.listdir(india_path):\n",
    "    lst.append(i)\n",
    "lst=lst[7]  \n",
    "state_path=os.path.join(india_path,lst)  \n",
    "print(state_path)\n",
    "\n",
    "transaction_data=[]\n",
    "for state in os.listdir(state_path):\n",
    "    state1_path=os.path.join(state_path,state)\n",
    "    \n",
    "    for year in os.listdir(state1_path):\n",
    "        year_path=os.path.join(state1_path,year)\n",
    "        \n",
    "        for file in os.listdir(year_path):\n",
    "            file_path=os.path.join(year_path,file)\n",
    "            quater=int(file.replace(\".json\",\"\"))\n",
    "            \n",
    "            with open (file_path,\"r\") as f:\n",
    "                data=json.load(f)\n",
    "                \n",
    "                if data.get(\"data\"):\n",
    "                    for d in data[\"data\"][\"districts\"]:\n",
    "                        entity_name_district=d[\"entityName\"]\n",
    "                        count_districts=d[\"metric\"][\"count\"]\n",
    "                        amount_district=d[\"metric\"][\"amount\"]\n",
    "                        \n",
    "                        \n",
    "                    if data.get(\"data\"):\n",
    "                        for p in data[\"data\"][\"pincodes\"]:\n",
    "                            entity_name_pincodes=p[\"entityName\"]   \n",
    "                            count_pincode=p[\"metric\"][\"count\"]\n",
    "                            amount_pincode=p[\"metric\"][\"amount\"]\n",
    "                        \n",
    "                        \n",
    "                            transaction_data.append({\n",
    "                        \"state\":state,\n",
    "                        \"year\":year,\n",
    "                        \"Quarter\":quater,\n",
    "                        \"entity_names_district\":entity_name_district,\n",
    "                        \"count_district\":count_districts,\n",
    "                        \"amount_district\":amount_district,\n",
    "                        \"entity_name_pincodes\":entity_name_pincodes,\n",
    "                        \"count_pincode\":count_pincode,\n",
    "                        \"amount_pincode\":amount_pincode})\n",
    "                    \n",
    "import pandas as pd\n",
    "dataset_top_transaction=pd.DataFrame(transaction_data)   \n",
    "dataset_top_transaction                     \n",
    "\n",
    "dataset_top_transaction.to_csv(\"top_transaction.csv\",index=False)                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6985e9",
   "metadata": {},
   "source": [
    "Top _user  9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73657700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\top\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\top\\user\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\top\\user\\country\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\top\\user\\country\\india\n",
      "C:\\Users\\Dell\\OneDrive - Havells\\Desktop\\DataScience\\pulse\\data\\top\\user\\country\\india\\state\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "base_path=\"C:\\\\Users\\\\Dell\\\\OneDrive - Havells\\\\Desktop\\\\DataScience\\\\pulse\"\n",
    "data=[]\n",
    "for i in os.listdir(base_path):\n",
    "    data.append(i) \n",
    "      \n",
    "data1=data[2]  \n",
    "data_path=os.path.join(base_path,data1)\n",
    "amu=[]\n",
    "for i in os.listdir(data_path):\n",
    "    amu.append(i)\n",
    "     \n",
    "amu=amu[2]\n",
    "amu_path=os.path.join(data_path,amu)\n",
    "print(amu_path)\n",
    "\n",
    "uti=[]\n",
    "for i in os.listdir(amu_path):\n",
    "    uti.append(i)\n",
    "      \n",
    "uti=uti[2] \n",
    "user_path=os.path.join(amu_path,uti)\n",
    "\n",
    "print(user_path)\n",
    "\n",
    "country=[]\n",
    "for i in os.listdir(user_path):\n",
    "    country.append(i)\n",
    "country=country[0]\n",
    "country_path=os.path.join(user_path,country)\n",
    "print(country_path)\n",
    "india=[]\n",
    "for i in os.listdir(country_path):\n",
    "    india.append(i)\n",
    "    \n",
    "india=india[0] \n",
    "india_path=os.path.join(country_path,india)   \n",
    "print(india_path)\n",
    "lst=[]\n",
    "for i in os.listdir(india_path):\n",
    "    lst.append(i)\n",
    "lst=lst[7]  \n",
    "state_path=os.path.join(india_path,lst)  \n",
    "print(state_path)\n",
    "\n",
    "user_data=[]\n",
    "for state in os.listdir(state_path):\n",
    "    state1_path=os.path.join(state_path,state)\n",
    "    \n",
    "    for year in os.listdir(state1_path):\n",
    "        year_path=os.path.join(state1_path,year)\n",
    "        \n",
    "        for file in os.listdir(year_path):\n",
    "            file_path=os.path.join(year_path,file)\n",
    "            quater=int(file.replace(\".json\",\"\"))\n",
    "            \n",
    "            with open (file_path,\"r\") as f:\n",
    "                data=json.load(f)\n",
    "                \n",
    "                if data[\"data\"]:\n",
    "                    for d in data[\"data\"][\"districts\"]:\n",
    "                        district_name=d[\"name\"]\n",
    "                        registered_users_district=d[\"registeredUsers\"]\n",
    "                        \n",
    "                        \n",
    "                    if data[\"data\"]:\n",
    "                        for p in data[\"data\"][\"pincodes\"]:\n",
    "                            pincodes_name=p[\"name\"]\n",
    "                            registered_users_pincodes=p[\"registeredUsers\"]\n",
    "                            \n",
    "                            \n",
    "                            user_data.append({\n",
    "                                \"state\":state,\n",
    "                                \"year\":year,\n",
    "                                \"Quater\":quater,\n",
    "                                \"district_name\":district_name,\n",
    "                                \"district_registered_users\":registered_users_district,\n",
    "                                \"pincode_names\":pincodes_name,\n",
    "                                \"pincode_registered_users\":registered_users_pincodes\n",
    "                                \n",
    "                            })\n",
    "                          \n",
    "df=pd.DataFrame(user_data) \n",
    "df.to_csv(\"Top_user.csv\",index=False)\n",
    "              \n",
    "                \n",
    "                \n",
    "#data_dictrict=pd.DataFrame(district_data)                            \n",
    "#data_pincode=pd.DataFrame(pincode_data)\n",
    "#data_dictrict.head()\n",
    "#data_pincode.head()\n",
    "#df_merge=pd.merge(data_dictrict,data_pincode,on=[\"state\",\"quater\",\"year\"] ,how=\"outer\")\n",
    "#df_merge\n",
    "#df_merge.to_csv(\"top_user.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
